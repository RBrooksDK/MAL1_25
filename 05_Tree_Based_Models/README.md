<h1 align="center">05 Tree Based Models</h1>

## Preparation

Chapters 6 and 7.

You will need to install the graphviz and pydotplus modules in python. You can do this by following these steps:

Open the anaconda prompt
Install graphviz by typing "conda install python-graphviz"
Install pydotplus by typing "conda install pydotplus"

## Material

[Decision Trees PDF](src/Decision%20Trees%20-%20X.pdf)

[Decision Trees 1 ipynb](src/Decision%20Trees%201%20-%20Visualization%20and%20hyperparameters.ipynb)

[Decision Trees 2 ipynb](src/Decision%20Trees%202%20-%20Feature%20importance%20and%20ensembles%20of%20trees.ipynb)

[Decision Trees 3 ipynb](src/Decision%20Trees%203%20-%20Gradient%20boosted%20trees%20for%20regression.ipynb)

[Optional Exercises DOCX](srC/Optional%20exercises.docx)

## Session Description

We will cover tree-based models.

### Learning Objectives

- Use and implement decision trees, random forests and gradient boosted decision trees in python.
- Describe the advantages and disadvantages of using decision trees, random forests and gradient boosted decision trees, respectively.
- Visualize decision trees in different ways.
- Extract and interpret feature importance.
- Describe how the Gini impurity index can be used to determine which feature to branch off on.
- Explain what is meant by pre-pruning.
- Explain how random forests are random, including what is meant by bootstrapping and feature selection in this context.
- Explain what is meant by soft voting.
- Discuss different hyperparameters of tree-based methods, and how tuning these parameters influence the results.
