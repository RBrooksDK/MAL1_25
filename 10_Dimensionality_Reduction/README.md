<h1 align="center">10 Dimensionality Reduction</h1>

## Preparation

Ch 8

## Material

[Session material](https://viaucdk-my.sharepoint.com/:f:/g/personal/rib_viauc_dk/Ejs8_uSSIJRFp4LkOr7Io7EB6YasdVaxRR0MFhOS9cXB8w?e=7OFxdn)

### Online Resources
- [Steve Brunton](https://youtube.com/playlist?list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv&si=q7-RepDmv-fnb5PH) has made a whole lecture series about the SVD. This is overkill but maybe check out the the Overview and the videoes about PCA.

 - For a very appealing and visual explanation of SVD, you should take a look at [Visual Kernel](https://www.youtube.com/watch?v=vSczTbgc8Rc&list=PLWhu9osGd2dB9uMG5gKBARmk73oHUUQZS&index=4)'s video on the topic.

Useful Resources on t-SNE (not curriculum related, but its useful to know about):

 - [How to Use t-SNE Effectively](https://distill.pub/2016/misread-tsne/)

 - [openTSNE](https://opentsne.readthedocs.io/en/stable/)

 - [Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)

I've also added the original research papers leading up to t-SNE (not part of syllabus, just there for reference)

If you want a really in depth introduction to t-SNE, look [here](https://www.youtube.com/watch?v=MnRskV3NY1k)

If you missed the session in linear algebra, I recommend checking out some of the resources mentioned above.

## Session Description

This lecture covers **unsupervised machine learning** algorithms. We discuss how these can be used for dimensionality reduction. 

### Key Concepts

- Principal component analysis (PCA)
- t-distributed stochastic neighbor embedding (t-SNE)

### Learning Objectives

- Use principle component analysis (PCA) to reduce the dimensions of your dataset
- Describe how PCA can be used for clustering analyses
- Create 2-dimensional clustering-plots in python using PCA and t-SNE

Note that t_SNE is not curriculum related, but it is a very useful tool for visualizing high-dimensional data. We will not ask you about it in the exam.